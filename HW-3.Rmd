---
title: "MATH 216 Homework 3"
author: "Jacob Dixon"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(Quandl))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(foreign))
suppressPackageStartupMessages(library(ggthemes))
suppressPackageStartupMessages(library(pander))
suppressPackageStartupMessages(library(knitr))
```


## Admistrative:

Please indicate

* Who you collaborated with: Alison Cook, Andrew Holtz
* Roughly how much time you spent on this HW: 14h
* What gave you the most trouble: Had to ask for a lot of help creating a loop for the bitcoin question, as that seemed like the best way to answer it - out of my knowledge zone though. spending a lot of time on these assignments. 
* Any comments you have: 


## Data

* You must first copy the file `profiles.csv` from `HW-2` to the `data` folder
in the `HW-3` directory
* We also consider all 222,540 songs played in the Reed College pool hall
jukebox from Nov 30, 2003 to Jan 22, 2009 (included in `HW-3` folder). 

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
profiles <- read.csv("data/profiles.csv", header=TRUE) %>% 
  tbl_df()
jukebox <- read.csv("data/jukebox.csv", header=TRUE) %>% 
  tbl_df()
```





## Question 1:

For this question we will be picking up from where we left off in HW-2,
specifically the OkCupid dataset.


### a)

Using your exploratory data analysis from HW-2, fit a logistic regression to 
predict individual's gender and interpret the results for one continuous variable 
(if you used one) and one categorical variable of your choice.

```{r, echo=FALSE, fig.width=12, fig.height=6}

#let's get this set up so I can do that, though my exploratory analysis did not include
#any continuous variables, I will use height so that I can have one here. 

#Seperate out the essays 
essays <- select(profiles, contains("essay"))
profiles <- select(profiles, -contains("essay"))

#add a binary column for females
profiles <- mutate(profiles, is_female = ifelse(sex=="f", 1, 0))

#Filter out the ones that do not identify, since that is what we are interested in
profiles <- filter(profiles, sex != "")

#Searching for words functions, first finding it, then returning found word 
find_query <- function(char.vector, query){
  which.has.query <- grep(query, char.vector, ignore.case = TRUE)
  length(which.has.query) != 0
}
profile_has_word <- function(data.frame, query){
  query <- tolower(query)
  has.query <- apply(data.frame, 1, find_query, query=query)
  return(has.query)
}

#Add a column with results for the word "baking" 
profiles$has_bake <- profile_has_word(data.frame = essays, query = "baking")


#Create a linear model that uses bake and heights to identify females
model1 <- glm(is_female ~ has_bake + height , data=profiles, family=binomial)
summary(model1)


```

The summary above is the output from a model fit to height data and whether or not a user has the word "bake" in one of their essays. The key part to focus on is under "estimate" for has_bake and for height. The values here represent to associated increases in the log odds of being female given increases of 1 inch in height and going from not having to having the word 'bake' in their essay profile.  


### b)

Plot a histogram of the fitted probabilities $\widehat{p}_i$ for all users $i=1,
\ldots, n=59946$ in your dataset.

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Create the fitted values 
fitted_values <- fitted(model1)

#Plot it, add a line at 50%, make the colors better
ggplot(data = NULL, aes(x=fitted_values))+
  theme_tufte()+
  geom_vline(xintercept = 0.5, color = "red")+
  geom_histogram(binwidth = 0.2, col = "blue", fill = "orange", alpha = 0.2)+
  labs(title = "Gender Distribution Based on Model", 
       x = "    <- more likely to be male      more likely to be female ->", 
       y = "Number of Individuals")

```

The histogram above shows what the model would predict the gender of a user to be, binned by the likelihood of being male "0" or female "1".  

### c)

Use a *decision threshold* of $p^*=0.5$ to make an explicit prediction for each
user $i$'s sex and save this in a variable `predicted_sex`. In other words, for user $i$

* If $\widehat{p}_i > p^*$, set `predicted_sex = 1` i.e. they are female
* If $\widehat{p}_i < p^*$, set `predicted_sex = 0` i.e. they are male

Display a 2 x 2 contigency table of `sex` and `predicted_sex` i.e. compare the 
predicted sex to the actual sex of all users. The sum of all the elements in
your table should be $n=59946$. Comment on how well our predictions fared.

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Do the prediction
gender_probability = fitted(model1, profiles, type="response")
gender_predict = rep(1, dim(profiles)[1])
gender_predict[gender_probability > 0.5] = 1

#Create output table
threshold_table <- table(gender_predict, profiles$is_female)
sum(threshold_table)
kable(threshold_table)

#Even with fitted, as you suggested, I am not able to get this to come out right

```

The table above shows the number of individuals that the model would predict as male "O" or female "1". It has a decision threshold, shown in red in part B, of 0.5. 

### d)

Say we wanted to have a **false positive rate** of about 20%, i.e. of the people
we predicted to be female, we want to be wrong no more than 20% of the time. What
decision threshold $p^*$ should we use?

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Don't understand this. 
```





## Question 2:

Using the jukebox data, plot a time series of the number of songs played each
week over the entire time period. i.e.

* On the x-axis present actual dates (not something like Week 93, which doesn't 
mean anything to most people).
* On the y-axis present the total number of songs.

What seasonal (i.e. cyclical) patterns do you observe?

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Separate out the combined date and time stamp 
jukebox <- jukebox %>% 
  mutate(formatted_date = parse_date_time(date_time, "%b %d %H%M%S %Y"))

#Do some more separating
jukebox <- jukebox %>% separate(formatted_date, c("Date", "Time"), sep = " ")

#Create a week column 
jukebox <- jukebox %>% mutate(week = week(Date))

#Create a year column
jukebox <- jukebox %>% mutate(year = year(Date))

#Because there are repeat weeks, i.e. week 48 happens each year, group by those
songs_per_week <- jukebox  %>% group_by(year, week)  %>% tally() 

#Add date back on to that bad boy 
songs_per_week$date <- as.Date(paste(songs_per_week$year, 
                                     songs_per_week$week, 1, sep="-"), "%Y-%U-%u")

#Plot that and see how it looks -> It looks like the middle of years has less, 
#makes sense, they won't be playing as many songs during the summer 
ggplot(data = songs_per_week, aes(x = date, y = n)) +
  theme_tufte()+
  geom_area()+
  labs(title = "Songs Played Throughout the Years", x = "Year",
       y = "Number of Songs Played")


#I want to just see the month, so select out that and the number of songs 
songs_per_week <- songs_per_week %>% mutate(month = month(date)) %>% select(month, n)

#Associate months with seasons 
winter <- c(12, 1, 2)
spring <- c(3, 4, 5)
summer <- c(6, 7, 8)
autumn <- c(9, 10, 11)

#Put those months into the previously created seasons
songs_by_season <- songs_per_week %>% 
  mutate(season = ifelse(month %in% winter, 'winter', 
                         ifelse(month %in% spring, 'spring', 
                                ifelse(month %in% summer, 'summer', 
                                       ifelse(month %in% autumn, 'autumn', NA)))))


#Now we can take a look at the songs and the different seasons
ggplot(data = songs_by_season, aes(x = season, y = n, colour = season)) +
  theme_tufte()+
  geom_boxplot()+
  guides(colour = "none")+
  labs(title = "Seasonal Song Variation", x = "Season", y = "Number of Songs Played")


```

The figures above show the number of songs played over several years on a jukebox. The first figure shows the total songs played throughout the years, and the second shows a more specific seasonal variation. While the first figure does demonstrate the dramatic changes in songs played, the second one more clearly shows how different parts of the school year are correlated with different amounts of songs played. The second figure also allows for the more specific comparison of seasons, rather than the overall pattern of school-year vs. non-school-year in the first figure. 



## Question 3:

Using the jukebox data, what are the top 10 artists played during the "graveyard
shift" during the academic year? Define

* the "graveyard shift" as midnight to 8am
* the academic year as September through May (inclusive)

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Add month to this
jukebox <- jukebox %>% mutate(month = month(Date))

#These are the acaemic months of the year
academic <- c(9, 10, 11, 12, 1, 2, 3, 4, 5)

#Group songs into the appropriate time of the year 
academic_songs <- jukebox %>% 
  mutate(academic = ifelse(month %in% academic, 'academic', 'break')) %>% 
  filter(academic == "academic")

#limit it to only graveyard times 
academic_songs <- academic_songs %>% filter(Time >= "00:00:00", Time <= "08:00:00")

#Now count the plays per artist, pick the top ten, make a table 
academic_songs %>% group_by(artist) %>% 
  tally() %>% arrange(desc(n)) %>% slice(1:10) %>% kable()


```

The table above shows the top 10 artists played during the “graveyard shift” during the academic year. 



## Question 4:

We want to compare the volatility of 

* bitcoin prices
* gold prices

Let our measure of volatility be the relative change from day-to-day in price. 
Let the reference currency be US dollars. Analyze these results and provide
insight to a foreign currency exchanger.

```{r, echo=FALSE, fig.width=12, fig.height=6}

#Bring in the bitcoin data
bitcoin <- Quandl("BAVERAGE/USD") %>% tbl_df()

#Bring in the gold/USD data 
gold <- Quandl("WGC/GOLD_DAILY_USD") %>% tbl_df


# We rename the variables so that they don't have spaces. You do that as follows
# using ` marks (next to the "1" key):
bitcoin <- rename(bitcoin, Avg = `24h Average`, Total.Volume = `Total Volume`)

#Parsing the date out, probably not necessary
bitcoin <- mutate(bitcoin, pars_date = ymd(Date))

#Join the two so I can graph them 
bit_gold <- left_join(bitcoin, gold, by = "Date")


#Calculate the dail difference in bitcoin and gold. Use (today_price - yesterday_price)
#/yesterday_price * 100. 
bitcoin_diff <- c()
for(i in 2:length(bit_gold$Date)) {
  bitcoin_diff[i-1] <- ((bit_gold$Avg[i] - bit_gold$Avg[i-1])/bit_gold$Avg[i-1])*100
}

bitcoin_diff <- as.data.frame(bitcoin_diff)
bitcoin_diff <- mutate(bitcoin_diff, Date = bit_gold$Date[-1])

gold_diff <- c()
for(i in 2:length(bit_gold$Date)) {
  gold_diff[i-1] <- ((bit_gold$Value[i] - bit_gold$Value[i-1])/bit_gold$Value[i-1])*100
}

gold_diff <- as.data.frame(gold_diff)
gold_diff <- mutate(gold_diff, Date = bit_gold$Date[-1])

#Join and create a table of difference in bitcoin and difference in gold for each day
currency_diff <- left_join(bitcoin_diff, gold_diff, by = "Date")
currency_diff <- currency_diff[,c(2,1,3)]
currency_diff <- gather(currency_diff, "currency", "diff", 2:3)


#Graph those changes over time 
ggplot(data = currency_diff, aes(x = Date, y = diff, fill = currency)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Gold v. Bitcoin", x = "Date",
       y = "Change in USD per day") +
  theme_tufte()+
  scale_fill_discrete(name = "Currency", labels = c("Bitcoin", "Gold"))


```


The figure above shows the change in average daily price of bitcoin and gold. By looking at the amplitude of the peaks, one can see that bitcoin varies much more than gold does. If I were to look for something to exchange my foreign currency for, the safe bet looks like it would be gold. There is a chance that I could make a lot of money by switching to bitcoin at the right time, but gold tends to be more stable over time. 
